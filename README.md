## Enhanced Fake News Detection Repository

This repository enhances the original collection of research papers on [Fake News Detection (FND)](https://github.com/wangbing1416/Awesome-Fake-News-Detection). Contributions are welcome to expand this list, email suggestions to raza.ul.haq@live.com to help build a comprehensive resource for the research community.
# Context-based FND

## Text-only Methods

### Supervised Learning

| Title                           | **Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection**                                                                                                                                                                                                                                                                                                                                                    |
|---------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Year                        | 2024                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Approach/Methodology        | The study involves an empirical investigation to understand the effectiveness of LLMs (e.g., GPT 3.5) in detecting fake news compared to SLMs like fine-tuned BERT. The authors designed an adaptive rationale guidance network (ARG) for fake news detection, which allows SLMs to leverage LLM-generated rationales for enhanced analysis. A rationale-free version, ARGD, was also developed for cost-sensitive use cases through distillation. |
| Datasets Used               | N/A                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| Results/Performance Metrics | ARG and ARGD outperformed three types of baseline methods, including those based on SLMs, LLMs, and their combinations.                                                                                                                                                                                                                                                                                                                            |
| Challenges                  | LLMs like GPT 3.5, despite offering desirable multi-perspective rationales, underperform compared to fine-tuned SLMs like BERT due to difficulties in selecting and integrating rationales effectively.                                                                                                                                                                                                                                            |
| Key Contribution            | The research highlights that while LLMs alone may not surpass fine-tuned SLMs in fake news detection, they can serve as valuable advisors by providing multi-perspective rationales. The adaptive rationale guidance network (ARG) is a significant contribution that allows SLMs to incorporate LLM insights selectively, along with the cost-effective, rationale-free ARGD variant.                                                             |
|                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| Title                           | **Learn over Past, Evolve for Future: Forecasting Temporal Trends for Fake News Detection**                                                                                                                                                                                                                                                                                                                                                        |
| Year                            | 2023                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Approach/Methodology            | FTT (Forecasting Temporal Trends) that forecasts the temporal distribution patterns of news data to guide the detector in adapting to future data distributions.                                                                                                                                                                                                                                                                                   |
| Datasets Used                   | Real-world temporally split dataset                                                                                                                                                                                                                                                                                                                                                                                                                |
| Results/Performance Metrics     | Demonstrated superiority of the proposed framework                                                                                                                                                                                                                                                                                                                                                                                                 |
| Challenges                      | Performance degradation due to training on past data and testing on future data caused by the temporal shift in news data.                                                                                                                                                                                                                                                                                                                         |
| Key Contribution                | Introduction of a framework FTT that forecasts temporal distribution patterns to improve the adaptability of fake news detectors to future data.                                                                                                                                                                                                                                                                                                   |
|                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| Title                           | **Faking Fake News for Real Fake News Detection: Propaganda-loaded Training Data Generation**                                                                                                                                                                                                                                                                                                                                                      |
| Year                            | 2023                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Approach/Methodology            | The paper proposes a novel framework for generating training examples informed by human-authored propaganda styles and strategies. It employs self-critical sequence training guided by natural language inference to validate generated articles and integrates propaganda techniques such as appeal to authority and loaded language.                                                                                                            |
| Datasets Used                   | A new training dataset, PROPANEWS, with 2,256 examples.                                                                                                                                                                                                                                                                                                                                                                                            |
| Results/Performance Metrics     | Improved fake news detection performance, achieving a 3.62‚Äì7.69% increase in F1 score on two public datasets.                                                                                                                                                                                                                                                                                                                                      |
| Challenges                      | The gap between machine-generated fake news and human-authored disinformation, including differences in style and intent.                                                                                                                                                                                                                                                                                                                          |
| Key Contribution                | Development of the PROPANEWS dataset and a framework that enhances the detection of human-written disinformation by incorporating known propaganda techniques.                                                                                                                                                                                                                                                                                     |
|                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| Title                           | **Zoom Out and Observe: News Environment Perception for Fake News Detection**                                                                                                                                                                                                                                                                                                                                                                      |
| Year                            | 2022                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Approach/Methodology            | Introduced the News Environment Perception Framework (NEP), which constructs a macro and micro news environment from recent mainstream media for each post. It uses a popularity-oriented and a novelty-oriented module to capture environmental signals and improve fake news detection.                                                                                                                                                          |
| Datasets Used                   | Newly built datasets for evaluating NEP.                                                                                                                                                                                                                                                                                                                                                                                                           |
| Results/Performance Metrics     | Demonstrated that NEP efficiently improves the performance of basic fake news detectors.                                                                                                                                                                                                                                                                                                                                                           |
| Challenges                      | Existing methods neglect the external news environment where fake news is created and disseminated.                                                                                                                                                                                                                                                                                                                                                |
| Key Contribution                | The development of the NEP framework that observes the broader news environment to enhance fake news detection performance.                                                                                                                                                                                                                                                                                                                        |
|                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| Title                           | **A Coarse-to-fine Cascaded Evidence-Distillation Neural Network for Explainable Fake News Detection**                                                                                                                                                                                                                                                                                                                                             |
| Year                            | 2022                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Approach/Methodology            | The paper proposed a Coarse-to-fine Cascaded Evidence-Distillation (CofCED) neural network for explainable fake news detection. It utilized a hierarchical encoder for web text representation and developed two cascaded selectors to pick the most explainable sentences from the top-ùêæ reports in a coarse-to-fine manner.                                                                                                                      |
| Datasets Used                   | Two explainable fake news datasets were constructed and made publicly available.                                                                                                                                                                                                                                                                                                                                                                   |
| Results/Performance Metrics     | The experimental results showed that the model significantly outperformed state-of-the-art baselines and generated high-quality explanations from various evaluation perspectives.                                                                                                                                                                                                                                                                 |
| Challenges                      | Existing methods tailored automated solutions on manual fact-checked reports, suffering from limited news coverage and debunking delays.                                                                                                                                                                                                                                                                                                           |
| Key Contribution                | The main contribution was the CofCED neural network that reduced dependency on fact-checked reports by leveraging raw reports and providing explainable fake news detection.                                                                                                                                                                                                                                                                       |
|                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| Title                           | **Demystifying Neural Fake News via Linguistic Feature-Based Interpretation**                                                                                                                                                                                                                                                                                                                                                                      |
| Year                            | 2022                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Approach/Methodology            | The paper conducted a feature-based study to understand the linguistic attributes most exploited by neural fake news generators. Models were trained on subsets of features and tested against increasingly advanced neural fake news to identify robust attributes.                                                                                                                                                                               |
| Datasets Used                   | N/A                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| Results/Performance Metrics     | It was found that stylistic features were the most robust in confronting neural fake news.                                                                                                                                                                                                                                                                                                                                                         |
| Challenges                      | The challenge discussed was understanding how to best confront misinformation generated by advanced neural fake news models.                                                                                                                                                                                                                                                                                                                       |
| Key Contribution                | The main contribution was the interpretative analysis identifying stylistic features as the most robust against neural fake news.                                                                                                                                                                                                                                                                                                                  |
|                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| Title                           | **Generalizing to the Future: Mitigating Entity Bias in Fake News Detection**                                                                                                                                                                                                                                                                                                                                                                      |
| Year                            | 2022                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Approach/Methodology            | The paper proposed an entity debiasing framework (ENDEF) that aimed to generalize fake news detection models to future data by mitigating entity bias from a cause-effect perspective. The causal graph among entities, news contents, and news veracity was modeled, and the direct effect of entities was removed during inference to reduce bias.                                                                                               |
| Datasets Used                   | English and Chinese datasets were used for offline experiments.                                                                                                                                                                                                                                                                                                                                                                                    |
| Results/Performance Metrics     | The framework significantly improved the performance of base fake news detectors in offline experiments, and its superiority was verified through online tests.                                                                                                                                                                                                                                                                                    |
| Challenges                      | Existing methods overlooked unintended entity bias in real-world data, affecting the models' generalization ability to future data.                                                                                                                                                                                                                                                                                                                |
| Key Contribution                | The main contribution was introducing the first framework to explicitly enhance the generalization ability of fake news detection models to future data by addressing entity bias.                                                                                                                                                                                                                                                                 |
|                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| Title                           | **Early Detection of Fake News with Multi-source Weak Social Supervision**                                                                                                                                                                                                                                                                                                                                                                         |
| Year                            | 2021                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Approach/Methodology            | The paper exploited multiple weak signals from different sources of user engagements with content (referred to as weak social supervision) and their complementary utilities for detecting fake news. It used a meta-learning framework to train a fake news detector by jointly leveraging limited clean data and weak signals, estimating the quality of different weak instances.                                                               |
| Datasets Used                   | Real-world datasets were used.                                                                                                                                                                                                                                                                                                                                                                                                                     |
| Results/Performance Metrics     | The proposed framework outperformed state-of-the-art baselines for early detection of fake news without using any user engagements during prediction.                                                                                                                                                                                                                                                                                              |
| Challenges                      | State-of-the-art systems faced challenges for early detection due to the rapidly evolving nature of news events and limited annotated data.                                                                                                                                                                                                                                                                                                        |
| Key Contribution                | The main contribution was the development of a framework that effectively used weak social supervision and meta-learning for early fake news detection.                                                                                                                                                                                                                                                                                            |
|                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| Title                           | **Mining Dual Emotion for Fake News Detection**                                                                                                                                                                                                                                                                                                                                                                                                    |
| Year                            | 2021                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Approach/Methodology            | The paper verified that dual emotion was distinctive between fake and real news and proposed Dual Emotion Features to represent this dual emotion and their relationship for fake news detection. The proposed features were designed to be compatible with existing fake news detectors for enhancement.                                                                                                                                          |
| Datasets Used                   | Three real-world datasets, one in English and two in Chinese.                                                                                                                                                                                                                                                                                                                                                                                      |
| Results/Performance Metrics     | The proposed feature set outperformed state-of-the-art emotional features related to the task and improved the performance of existing fake news detectors.                                                                                                                                                                                                                                                                                        |
| Challenges                      | Existing methods focused only on publisher emotions and did not consider the high-arousal emotions evoked in the crowd (social emotions).                                                                                                                                                                                                                                                                                                          |
| Key Contribution                | The main contribution was the introduction of Dual Emotion Features, representing both publisher and social emotions, which enhanced fake news detection models.                                                                                                                                                                                                                                                                                   |
|                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| Title                           | **Fake News Detection via NLP is Vulnerable to Adversarial Attacks**                                                                                                                                                                                                                                                                                                                                                                               |
| Year                            | 2019                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Approach/Methodology            | The paper argued that existing models focusing solely on linguistic aspects without fact-checking were prone to misclassify fact-tampering fake news and under-written real news. It highlighted the importance of combining fact-checking with linguistic analysis and proposed a crowdsourced knowledge graph as a preliminary solution for collecting timely facts.                                                                             |
| Datasets Used                   | N/A                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| Results/Performance Metrics     | Experiments on Fakebox, a state-of-the-art fake news detector, demonstrated the effectiveness of fact-tampering attacks and highlighted the need for improved methodologies.                                                                                                                                                                                                                                                                       |
| Challenges                      | The main challenge discussed was the risk of misclassification by models that did not incorporate fact-checking.                                                                                                                                                                                                                                                                                                                                   |
| Key Contribution                | The key contribution was the proposal of integrating fact-checking with linguistic analysis and the introduction of a crowdsourced knowledge graph as a potential solution for enhancing fake news detection.                                                                                                                                                                                                                                      |
